{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIuzZH7gj7Yu"
      },
      "source": [
        "\n",
        "\n",
        "> Import libraries to use\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1n-L9pacjmBA"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i38qZPSHmDVs"
      },
      "source": [
        ">  # Introduction to numpy (Skip if you already are familiar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wFkLk1kmeIn"
      },
      "source": [
        ">> Creating a 1D array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-o1XD0Qmgxk",
        "outputId": "2395a6a7-d0b4-4f8e-a98c-e766a0c7e5ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 2 3 4]\n"
          ]
        }
      ],
      "source": [
        "a = np.array([1,2,3,4])\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWh4Q90Gmh32"
      },
      "source": [
        ">> Creating a 2D array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOS0jF1AmjTX",
        "outputId": "c8122a40-1e9c-4ba5-83c2-1d41e9385ef6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [3 4]]\n"
          ]
        }
      ],
      "source": [
        "a = np.array([[1,2],[3,4]])\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z_7BfvcmoPA"
      },
      "source": [
        ">> Creating an array full of zeros\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdGvmJ7gmFrF",
        "outputId": "63c4c69c-eb21-4129-9c0b-e7cdd445d169"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[[0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "a = np.zeros(shape=(10))\n",
        "print(a)\n",
        "a = np.zeros(shape=(5,2))\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV2byWmWmr9g"
      },
      "source": [
        ">> Infinity in numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SMPoECVmygc",
        "outputId": "5e874d5f-ef3f-445a-99c3-517c9d5d8cb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inf\n"
          ]
        }
      ],
      "source": [
        "print(np.inf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCi8vs49mz44"
      },
      "source": [
        ">> Max and Argmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ailb-V76nSqc",
        "outputId": "1e8e5efa-f4f9-44fe-fdb9-ae5b2fb4087f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "a = np.array([2,1,4,3])\n",
        "print(np.max(a))\n",
        "print(np.argmax(a))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XpkQzTfnXMU"
      },
      "source": [
        ">> From list to Numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wdFdBaOncQI",
        "outputId": "bf7fd33b-de23-40f1-e31a-c1d1ebb6606d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4]\n",
            "[1 2 3 4]\n"
          ]
        }
      ],
      "source": [
        "l = [1,2,3,4]\n",
        "print(l)\n",
        "print(np.asarray(l))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgNawY2LngKt"
      },
      "source": [
        ">> Random in numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyopXlWsnjK1",
        "outputId": "38f4b29c-4737-491a-98b8-12f50812b9e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[8 2]\n",
            " [4 7]\n",
            " [8 8]\n",
            " [5 5]\n",
            " [9 7]]\n"
          ]
        }
      ],
      "source": [
        "# Array of Random integers ranging from 1 to 10 (with any size you want)\n",
        "a = np.random.randint(low=1, high=10, size=(5,2))\n",
        "print(a)\n",
        "\n",
        "# Array of random elements of a list with any size you want\n",
        "a = np.random.choice([0,1,2], size=(2,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abjqoNDSoAD6"
      },
      "source": [
        ">> Shapes in numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vN2gUoZEoCbE",
        "outputId": "f9cbdcc1-4550-488f-b569-7f84ffd552a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4, 2)\n",
            "[[2 3]\n",
            " [4 4]\n",
            " [4 2]\n",
            " [2 2]]\n",
            "(8, 1)\n",
            "[[2]\n",
            " [3]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [2]\n",
            " [2]\n",
            " [2]]\n"
          ]
        }
      ],
      "source": [
        "a = np.random.randint(low=1, high=5, size=(4,2))\n",
        "print(a.shape)\n",
        "print(a)\n",
        "\n",
        "# Reshape a to a vector of shape = (8,1)\n",
        "a = a.reshape((8,1))\n",
        "print(a.shape)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekYrPhAGkAfM"
      },
      "source": [
        "# Pre-defined utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "3kXEezQ_jnoP"
      },
      "outputs": [],
      "source": [
        "\n",
        "int_to_char = {\n",
        "    0 : 'u',\n",
        "    1 : 'r',\n",
        "    2 : 'd',\n",
        "    3 : 'l'\n",
        "}\n",
        "\n",
        "policy_one_step_look_ahead = {\n",
        "    0 : [-1,0],\n",
        "    1 : [0,1],\n",
        "    2 : [1,0],\n",
        "    3 : [0,-1]\n",
        "}\n",
        "\n",
        "def policy_int_to_char(pi,n):\n",
        "\n",
        "    pi_char = ['']\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "\n",
        "            if i == 0 and j == 0 or i == n-1 and j == n-1:\n",
        "\n",
        "                continue\n",
        "\n",
        "            pi_char.append(int_to_char[pi[i,j]])\n",
        "\n",
        "    pi_char.append('')\n",
        "\n",
        "    return np.asarray(pi_char).reshape(n,n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zlRobQekELk"
      },
      "source": [
        "# 1- Policy evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "N7_2lpTAkHAJ"
      },
      "outputs": [],
      "source": [
        "def policy_evaluation(n,pi,v,Gamma,threshhold):\n",
        "  \"\"\"\n",
        "    This function should return the value function that follows the policy pi.\n",
        "    Use the stopping criteria given in the problem statement.\n",
        "  \"\"\"\n",
        "  while True:\n",
        "    delta = 0.0 # Initialize the maximum change in value function\n",
        "    v_new = np.copy(v)\n",
        "\n",
        "    for i in range(n):\n",
        "      for j in range(n):\n",
        "        \n",
        "        # Skip terminal states\n",
        "        if (i == 0 and j == 0) or (i == n - 1 and j == n - 1):\n",
        "          v_new[i, j] = 0.0\n",
        "          continue\n",
        "\n",
        "        action = pi[i, j]\n",
        "        \n",
        "        move = policy_one_step_look_ahead[action]\n",
        "        next_i, next_j = i + move[0], j + move[1]\n",
        "\n",
        "        # Stay in the same state if we leave the grid\n",
        "        if next_i < 0 or next_i >= n or next_j < 0 or next_j >= n:\n",
        "          next_i, next_j = i, j \n",
        "\n",
        "        reward = -1\n",
        "\n",
        "        # Calculate the new value with the Bellman equation\n",
        "        new_val = reward + Gamma * v[next_i, next_j]\n",
        "        \n",
        "        delta = max(delta, np.abs(new_val - v[i, j]))\n",
        "\n",
        "        v_new[i, j] = new_val\n",
        "    \n",
        "    v = v_new\n",
        "\n",
        "    if delta < threshhold:\n",
        "      break\n",
        "      \n",
        "  return v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id0Re9bnkWRP"
      },
      "source": [
        "# 2- Policy improvement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "eC8zswV7kZPF"
      },
      "outputs": [],
      "source": [
        "def policy_improvement(n,pi,v,Gamma):\n",
        "  \"\"\"\n",
        "    This function should return the new policy by acting in a greedy manner.\n",
        "    The function should return as well a flag indicating if the output policy\n",
        "    is the same as the input policy.\n",
        "\n",
        "    Example:\n",
        "      return new_pi, True if new_pi = pi for all states\n",
        "      else return new_pi, False\n",
        "  \"\"\"\n",
        "  pi_stable = True \n",
        "  new_pi = np.copy(pi)\n",
        "\n",
        "  for i in range(n):\n",
        "    for j in range(n):\n",
        "      \n",
        "      # Skip terminal states\n",
        "      if (i == 0 and j == 0) or (i == n - 1 and j == n - 1):\n",
        "        continue\n",
        "\n",
        "      old_action = pi[i, j]\n",
        "      action_values = []  \n",
        "\n",
        "      for action in range(4): \n",
        "        move = policy_one_step_look_ahead[action]\n",
        "        next_i, next_j = i + move[0], j + move[1]\n",
        "\n",
        "        # Stay in the same state if we leave the grid\n",
        "        if next_i < 0 or next_i >= n or next_j < 0 or next_j >= n:\n",
        "          next_i, next_j = i, j\n",
        "        \n",
        "        reward = -1\n",
        "        \n",
        "        # Calculate the value for this action with the Bellman equation\n",
        "        val = reward + Gamma * v[next_i, next_j]\n",
        "        action_values.append(val)\n",
        "      \n",
        "      # Use the greedy policy\n",
        "      best_action = np.argmax(action_values)\n",
        "\n",
        "      new_pi[i, j] = best_action\n",
        "\n",
        "      if old_action != best_action:\n",
        "        pi_stable = False\n",
        "\n",
        "  return new_pi, pi_stable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rJLFmZYk0I1"
      },
      "source": [
        "# 3- Policy Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "xpuOHJeIk2K_"
      },
      "outputs": [],
      "source": [
        "def policy_initialization(n):\n",
        "  \"\"\"\n",
        "    This function should return the initial random policy for all states.\n",
        "  \"\"\"\n",
        "  policy = np.random.randint(low=0, high=4, size=(n, n))\n",
        "  return policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2, 3, 2, 1],\n",
              "       [1, 1, 1, 0],\n",
              "       [3, 0, 1, 0],\n",
              "       [0, 2, 2, 1]], dtype=int32)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "policy_initialization(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfeVN5fQlBt8"
      },
      "source": [
        "# 4- Policy Iteration algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "g7hnjz0PlFD4"
      },
      "outputs": [],
      "source": [
        "def policy_iteration(n,Gamma,threshhold):\n",
        "\n",
        "    pi = policy_initialization(n=n)\n",
        "\n",
        "    v = np.zeros(shape=(n,n))\n",
        "\n",
        "    while True:\n",
        "\n",
        "        v = policy_evaluation(n=n,v=v,pi=pi,threshhold=threshhold,Gamma=Gamma)\n",
        "\n",
        "        pi , pi_stable = policy_improvement(n=n,pi=pi,v=v,Gamma=Gamma)\n",
        "\n",
        "        if pi_stable:\n",
        "\n",
        "            break\n",
        "\n",
        "    return pi , v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FvleqV5onq9"
      },
      "source": [
        "# Main Code to Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hntGpzW-jZk3",
        "outputId": "7cef0988-b63c-46cd-d047-0c1e33c72e39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Gamma =  0.8\n",
            "\n",
            "[['' 'l' 'l' 'd']\n",
            " ['u' 'u' 'u' 'd']\n",
            " ['u' 'u' 'r' 'd']\n",
            " ['u' 'r' 'r' '']]\n",
            "\n",
            "\n",
            "[[ 0.   -1.   -1.8  -2.44]\n",
            " [-1.   -1.8  -2.44 -1.8 ]\n",
            " [-1.8  -2.44 -1.8  -1.  ]\n",
            " [-2.44 -1.8  -1.    0.  ]]\n",
            "\n",
            "Gamma =  0.9\n",
            "\n",
            "[['' 'l' 'l' 'd']\n",
            " ['u' 'u' 'u' 'd']\n",
            " ['u' 'u' 'r' 'd']\n",
            " ['u' 'r' 'r' '']]\n",
            "\n",
            "\n",
            "[[ 0.   -1.   -1.9  -2.71]\n",
            " [-1.   -1.9  -2.71 -1.9 ]\n",
            " [-1.9  -2.71 -1.9  -1.  ]\n",
            " [-2.71 -1.9  -1.    0.  ]]\n"
          ]
        }
      ],
      "source": [
        "n = 4\n",
        "\n",
        "Gamma = [0.8,0.9]\n",
        "\n",
        "threshhold = 1e-4\n",
        "\n",
        "for _gamma in Gamma:\n",
        "\n",
        "    pi , v = policy_iteration(n=n,Gamma=_gamma,threshhold=threshhold)\n",
        "\n",
        "    pi_char = policy_int_to_char(n=n,pi=pi)\n",
        "\n",
        "    print()\n",
        "    print(\"Gamma = \",_gamma)\n",
        "\n",
        "    print()\n",
        "\n",
        "    print(pi_char)\n",
        "\n",
        "    print()\n",
        "    print()\n",
        "\n",
        "    print(v)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Policy Iteration fails for Gamma = 1 because *policy_evaluation* enters an infinite loop if the policy has a cycle (like staying in place), as the value calculation never converges."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Q1 Value iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def value_iteration(n, Gamma, threshhold):\n",
        "  \"\"\"\n",
        "    This function implements the Value Iteration algorithm.\n",
        "    It returns the optimal policy and the optimal value function.\n",
        "  \"\"\"\n",
        "\n",
        "  v = np.zeros(shape=(n, n))\n",
        "  \n",
        "  while True:\n",
        "    delta = 0.0\n",
        "    v_new = np.copy(v) \n",
        "\n",
        "    for i in range(n):\n",
        "      for j in range(n):\n",
        "        \n",
        "        if (i == 0 and j == 0) or (i == n - 1 and j == n - 1):\n",
        "          v_new[i, j] = 0.0\n",
        "          continue\n",
        "          \n",
        "        action_values = []  # Pour stocker les valeurs des 4 actions possibles\n",
        "        \n",
        "        for action in range(4):\n",
        "          move = policy_one_step_look_ahead[action]\n",
        "          next_i, next_j = i + move[0], j + move[1]\n",
        "          \n",
        "          if next_i < 0 or next_i >= n or next_j < 0 or next_j >= n:\n",
        "            next_i, next_j = i, j\n",
        "            \n",
        "          reward = -1\n",
        "\n",
        "          q_value = reward + Gamma * v[next_i, next_j]\n",
        "          action_values.append(q_value)\n",
        "          \n",
        "        best_value = np.max(action_values)\n",
        "        \n",
        "        delta = max(delta, np.abs(best_value - v[i, j]))\n",
        "\n",
        "        v_new[i, j] = best_value\n",
        "\n",
        "    v = v_new\n",
        "\n",
        "    if delta < threshhold:\n",
        "      break\n",
        "  \n",
        "  pi = np.zeros(shape=(n, n), dtype=int)  \n",
        "  \n",
        "  for i in range(n):\n",
        "    for j in range(n):\n",
        "      if (i == 0 and j == 0) or (i == n - 1 and j == n - 1):\n",
        "        continue  \n",
        "        \n",
        "      action_values = []\n",
        "      for action in range(4):\n",
        "        move = policy_one_step_look_ahead[action]\n",
        "        next_i, next_j = i + move[0], j + move[1]\n",
        "        \n",
        "        if next_i < 0 or next_i >= n or next_j < 0 or next_j >= n:\n",
        "          next_i, next_j = i, j\n",
        "          \n",
        "        reward = -1\n",
        "        q_value = reward + Gamma * v[next_i, next_j]\n",
        "        action_values.append(q_value)\n",
        "        \n",
        "      best_action = np.argmax(action_values)\n",
        "      pi[i, j] = best_action\n",
        "      \n",
        "  return pi, v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Gamma =  0.8\n",
            "\n",
            "[['' 'l' 'l' 'd']\n",
            " ['u' 'u' 'u' 'd']\n",
            " ['u' 'u' 'r' 'd']\n",
            " ['u' 'r' 'r' '']]\n",
            "\n",
            "\n",
            "[[ 0.   -1.   -1.8  -2.44]\n",
            " [-1.   -1.8  -2.44 -1.8 ]\n",
            " [-1.8  -2.44 -1.8  -1.  ]\n",
            " [-2.44 -1.8  -1.    0.  ]]\n",
            "\n",
            "Gamma =  0.9\n",
            "\n",
            "[['' 'l' 'l' 'd']\n",
            " ['u' 'u' 'u' 'd']\n",
            " ['u' 'u' 'r' 'd']\n",
            " ['u' 'r' 'r' '']]\n",
            "\n",
            "\n",
            "[[ 0.   -1.   -1.9  -2.71]\n",
            " [-1.   -1.9  -2.71 -1.9 ]\n",
            " [-1.9  -2.71 -1.9  -1.  ]\n",
            " [-2.71 -1.9  -1.    0.  ]]\n",
            "\n",
            "Gamma =  1.0\n",
            "\n",
            "[['' 'l' 'l' 'd']\n",
            " ['u' 'u' 'u' 'd']\n",
            " ['u' 'u' 'r' 'd']\n",
            " ['u' 'r' 'r' '']]\n",
            "\n",
            "\n",
            "[[ 0. -1. -2. -3.]\n",
            " [-1. -2. -3. -2.]\n",
            " [-2. -3. -2. -1.]\n",
            " [-3. -2. -1.  0.]]\n"
          ]
        }
      ],
      "source": [
        "n = 4\n",
        "\n",
        "Gamma = [0.8, 0.9, 1.0] \n",
        "\n",
        "threshhold = 1e-4\n",
        "\n",
        "for _gamma in Gamma:\n",
        "\n",
        "    pi , v = value_iteration(n=n, Gamma=_gamma, threshhold=threshhold)\n",
        "\n",
        "    pi_char = policy_int_to_char(n=n, pi=pi)\n",
        "\n",
        "    print()\n",
        "    print(\"Gamma = \",_gamma)\n",
        "\n",
        "    print()\n",
        "\n",
        "    print(pi_char)\n",
        "\n",
        "    print()\n",
        "    print()\n",
        "\n",
        "    print(v)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the new function *value_iteration*, the situation Gamma = 1 works because it avoids that infinite loop. It skips *policy_evaluation* entirely by merging *policy_improvement*'s max operator into its main update loop, allowing it to converge by always picking the best action."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.13.0)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
